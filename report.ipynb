{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e15333f4",
   "metadata": {},
   "source": [
    "# Program 4: Benchmarking Heaps\n",
    "### Mikhail Filippov\n",
    "\n",
    "---\n",
    "In this assigment, we will implement **three** approaches to heapifying an array. The three approaches will be:\n",
    "1. Insertion Method: Insert elements one at a time into the heap\n",
    "2. Bubble down until value is bigger than both children (we'll call this \"Bubble Method 1\")\n",
    "3. Bubble down all the way, then bubble up until value is smaller than parent (we'll call this \"Bubble Method 2\")\n",
    "\n",
    "With each one, we will benchmark on **sorted**, **reverse sorted**, and **random** arrays to test the `heapify` method and analyze using regression techniques to estimate asymptotic time complexity for each case.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ec85d3",
   "metadata": {},
   "source": [
    "### Planned Approach\n",
    "For our three cases to benchmark, we will be using **sorted**, **reverse sorted**, and **randomly shuffled** lists to heapify with each approach. Generating each list won't be too much of a problem, and we will increase the size of each list linearly to look at the graphs and slopes generated by the dependant time output by the benchmarks.\n",
    "\n",
    "Expected results and predictions:\n",
    "1. Insertion method: We know that an insertion takes $O(log(n))$ time, so to insert $n$ number of elements, we should get a time complexity of $O(n\\times log(n))$. Since we are inserting at the end of the heap and bubbling up, the expected best case should be a **reverse sorted** list, as we will be adding the biggest element at `A[0]` first, followed by all elements at `A[i]` with $i \\gt 0$, with each element `A[i+1]` $\\lt$ `A[i]`. This allows for all smaller elements to be added to the bottom and not needed to be bubbled up. This, should, reduce our best case runtime to $O(n)$, as we are adding elements in costant time $n$ number of times now.\n",
    "2. Bubble Method 1: We know the recurrence relation for this method is $T(n)=2T(\\frac{n}{2}) + \\Theta(log(n))$. In the best case though, **reverse sorted** again, the $\\Theta(log(n))$ part is insignificant. This reduces our recurrence to $T(n)=2T(\\frac{n}{2}) + \\Theta(1)$ since we still need to call `BubbleDown`. This is still reduced to $O(n)$, but it should theoretically run faster than any other case.\n",
    "3. Bubble Method 2: This approach's best case should be the **sorted** list. This happens since no matter what, we bubble each value down **all** the way, and bubble back up *until the value is smaller than parent*. In a sorted list, this ensures that all of the smaller values will be bubbled down to the end and won't have to be bubble back up. The asymptotic running time for this should be $O(n)$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f223f00",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
